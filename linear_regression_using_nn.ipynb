{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import d2l.torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2,-3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_iter = load_array((features,labels),batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0113, -0.9103],\n",
       "         [ 0.4683, -0.9330],\n",
       "         [ 1.3758, -0.6145],\n",
       "         [-1.5056, -0.3307],\n",
       "         [-1.4590,  0.0919],\n",
       "         [ 0.7053,  0.3318],\n",
       "         [-1.4014, -0.3325],\n",
       "         [ 1.0628, -0.6507],\n",
       "         [-1.1701, -0.8366],\n",
       "         [-0.8277,  1.1882]]),\n",
       " tensor([[ 7.3075],\n",
       "         [ 8.3158],\n",
       "         [ 9.0425],\n",
       "         [ 2.3050],\n",
       "         [ 0.9865],\n",
       "         [ 4.4830],\n",
       "         [ 2.5218],\n",
       "         [ 8.5276],\n",
       "         [ 4.7049],\n",
       "         [-1.4921]])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Sequential将数据传入第一层，将第一层的输出作为第二层的输入\n",
    "# 参数为多个模型层\n",
    "# 这里只有一个输入形状为2，输出形状为1的全连接层\n",
    "net = nn.Sequential(nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net[0]表示网络中的第一层\n",
    "# 使用 weight.data, bias.data 访问参数\n",
    "net[0].weight.data.normal_(0,0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均方损失函数  Mean Square Error Loss\n",
    "loss = nn.MSELoss()\n",
    "# 作业2:用HuberLoss()替代MSELoss()\n",
    "#loss = nn.HuberLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.2368545532\n",
      "epoch 2, loss 0.4685491621\n",
      "epoch 3, loss 0.0021268663\n",
      "epoch 4, loss 0.0000584357\n",
      "epoch 5, loss 0.0000521452\n",
      "epoch 6, loss 0.0000523065\n",
      "epoch 7, loss 0.0000522862\n",
      "epoch 8, loss 0.0000523922\n",
      "epoch 9, loss 0.0000523477\n",
      "epoch 10, loss 0.0000522279\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter:\n",
    "        # 对于每个batch，计算loss函数，并得到其梯度，参数减去单位学习率*梯度进行更新\n",
    "        l = loss(net(X),y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    # 当所有batch遍历完后，该轮学习结束，计算该轮的损失函数\n",
    "    l = loss(net(features),labels)\n",
    "    # 在本轮的参数结果之上，进行下一轮学习\n",
    "    print(f'epoch {epoch + 1}, loss {l:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的误差： tensor([0.0001, 0.0001])\n",
      "b的误差： tensor([0.0002])\n"
     ]
    }
   ],
   "source": [
    "# 获取参数\n",
    "w = net[0].weight.data\n",
    "b = net[0].bias.data\n",
    "\n",
    "# 求误差\n",
    "print(\"w的误差：\", true_w-w.reshape(true_w.shape)) #这里 true_w 为列向量，但 w 为行向量，无法直接操作\n",
    "print(\"b的误差：\", true_b-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0019])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取参数梯度\n",
    "net[0].weight.grad\n",
    "net[0].bias.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
